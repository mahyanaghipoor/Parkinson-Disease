{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fb5b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3\\analysis_results3.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(healthy_data, sick_data, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_healthy_stat, shapiro_healthy_p = shapiro(healthy_data)\n",
    "    shapiro_sick_stat, shapiro_sick_p = shapiro(sick_data)\n",
    "    \n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_healthy_p > 0.05 and shapiro_sick_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از t-test استفاده می‌کنیم\n",
    "        t_stat, p_value = ttest_ind(healthy_data, sick_data, equal_var=False)\n",
    "        test_used = \"t-test\"\n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Mann-Whitney U test استفاده می‌کنیم\n",
    "        u_stat, p_value = mannwhitneyu(healthy_data, sick_data, alternative='two-sided')\n",
    "        test_used = \"Mann-Whitney U test\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    healthy_mean = healthy_data.mean()\n",
    "    sick_mean = sick_data.mean()\n",
    "    healthy_std = healthy_data.std()\n",
    "    sick_std = sick_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Healthy Mean': healthy_mean,\n",
    "        'Sick Mean': sick_mean,\n",
    "        'Healthy Std': healthy_std,\n",
    "        'Sick Std': sick_std,\n",
    "        'Shapiro Healthy p-value': shapiro_healthy_p,\n",
    "        'Shapiro Sick p-value': shapiro_sick_p,\n",
    "        'p-value (t-test/U-test)': p_value,\n",
    "        'Test Used': test_used  # نتیجه تست آماری که استفاده شده\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به گروه سالم و بیمار\n",
    "    healthy_data = df.iloc[:13]['Individual Means']  # 13 نفر سالم\n",
    "    sick_data = df.iloc[13:]['Individual Means']     # 113 نفر بیمار\n",
    "    \n",
    "    # تحلیل آماری برای هر فایل\n",
    "    analyze_group_statistics(healthy_data, sick_data, sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3\\analysis_results3.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee705fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group1_name, group2_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    \n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از t-test استفاده می‌کنیم\n",
    "        t_stat, p_value = ttest_ind(group1_data, group2_data, equal_var=False)\n",
    "        test_used = \"t-test\"\n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Mann-Whitney U test استفاده می‌کنیم\n",
    "        u_stat, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')\n",
    "        test_used = \"Mann-Whitney U test\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'p-value (t-test/U-test)': p_value,\n",
    "        'Test Used': test_used  # نتیجه تست آماری که استفاده شده\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", sheet_name)\n",
    "    analyze_group_statistics(group2_data, group3_data, \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "    analyze_group_statistics(group1_data, group3_data, \"Group 1 (1-13)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67a55c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1_three.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used  # نتیجه تست آماری که استفاده شده\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1_three.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc6ee7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikit_posthocs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_tukeyhsd\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscikit_posthocs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# بارگذاری داده‌ها از فایل اکسل\u001b[39;00m\n\u001b[0;32m      8\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/individual_means.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit_posthocs'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            dunn_results = sp.posthoc_dunn(data_combined, labels)\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/analysis_results3_withPosthoc.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47cc6640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikit-posthocs (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for scikit-posthocs\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-posthocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3831c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pingouin (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pingouin\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "249e91ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1_withPosthoc.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            # اجرای Dunn's Test به کمک فاصله جفتی (pairwise) و استفاده از مدل داده‌های اصلی\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            dist_matrix = pdist(data_combined.values.reshape(-1, 1))\n",
    "            square_dist = squareform(dist_matrix)\n",
    "            dunn_results = square_dist  # برای تست Dunn's باید محاسبات بیشتری انجام دهیم\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient1/analysis_results1_withPosthoc.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d95176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/analysis_results2_withPosthoc.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7593c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikit_posthocs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_tukeyhsd\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pdist, squareform\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscikit_posthocs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# بارگذاری داده‌ها از فایل اکسل\u001b[39;00m\n\u001b[0;32m      9\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit_posthocs'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            dunn_results = sp.posthoc_dunn(data_combined, groups=labels, p_adjust='bonferroni')\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/analysis_results2_withPosthoc2.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a704ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30d6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-posthocs\n",
      "  Downloading scikit_posthocs-0.11.4-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.9.0 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (1.14.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (0.14.4)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (2.2.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-posthocs) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mahya\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mahya\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->scikit-posthocs) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib->scikit-posthocs) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\mahya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels->scikit-posthocs) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahya\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.17.0)\n",
      "Downloading scikit_posthocs-0.11.4-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: scikit-posthocs\n",
      "Successfully installed scikit-posthocs-0.11.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-posthocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecea330",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "posthoc_dunn() got an unexpected keyword argument 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m     group3_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m126\u001b[39m:\u001b[38;5;241m179\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndividual Means\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# گروه سوم: 53 نفر (از 127 تا 179)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# تحلیل آماری برای مقایسه گروه‌ها\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     \u001b[43manalyze_group_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup1_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup2_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup3_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGroup 1 (1-13)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGroup 2 (14-126)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGroup 3 (127-179)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# تبدیل نتایج به DataFrame\u001b[39;00m\n\u001b[0;32m     90\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36manalyze_group_statistics\u001b[1;34m(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status)\u001b[0m\n\u001b[0;32m     45\u001b[0m     data_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([group1_data, group2_data, group3_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     46\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [group1_name] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(group1_data) \u001b[38;5;241m+\u001b[39m [group2_name] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(group2_data) \u001b[38;5;241m+\u001b[39m [group3_name] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(group3_data)\n\u001b[1;32m---> 47\u001b[0m     dunn_results \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposthoc_dunn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_adjust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbonferroni\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     dunn_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo significant differences found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: posthoc_dunn() got an unexpected keyword argument 'groups'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            dunn_results = sp.posthoc_dunn(data_combined, groups=labels, p_adjust='bonferroni')\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/analysis_results2_withPosthoc2.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c18ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/analysis_results2_withPosthoc2.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            \n",
    "            # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "            dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/analysis_results2_withPosthoc2.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc57a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae266982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results2.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results2.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa605112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # تبدیل نتایج Dunn's Test به یک DataFrame ۳x۳\n",
    "        dunn_results_df = pd.DataFrame(dunn_results, columns=[group1_name, group2_name, group3_name], index=[group1_name, group2_name, group3_name])\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results_df\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame برای نتایج پس‌هاک\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d34f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # تبدیل نتایج Dunn's Test به یک DataFrame ۳x۳ با نام گروه‌ها\n",
    "        dunn_results_df = pd.DataFrame(dunn_results, columns=[group1_name, group2_name, group3_name], index=[group1_name, group2_name, group3_name])\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results_df\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Non-Hospital\", \"Hospital\", \"Healthy\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame برای نتایج پس‌هاک\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec26bc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value between Group 1 (1-13) and Group 1 (1-13): nan\n",
      "P-value between Group 1 (1-13) and Group 2 (14-126): nan\n",
      "P-value between Group 1 (1-13) and Group 3 (127-179): nan\n",
      "P-value between Group 2 (14-126) and Group 1 (1-13): nan\n",
      "P-value between Group 2 (14-126) and Group 2 (14-126): nan\n",
      "P-value between Group 2 (14-126) and Group 3 (127-179): nan\n",
      "P-value between Group 3 (127-179) and Group 1 (1-13): nan\n",
      "P-value between Group 3 (127-179) and Group 2 (14-126): nan\n",
      "P-value between Group 3 (127-179) and Group 3 (127-179): nan\n",
      "P-value between Group 1 (1-13) and Group 1 (1-13): nan\n",
      "P-value between Group 1 (1-13) and Group 2 (14-126): nan\n",
      "P-value between Group 1 (1-13) and Group 3 (127-179): nan\n",
      "P-value between Group 2 (14-126) and Group 1 (1-13): nan\n",
      "P-value between Group 2 (14-126) and Group 2 (14-126): nan\n",
      "P-value between Group 2 (14-126) and Group 3 (127-179): nan\n",
      "P-value between Group 3 (127-179) and Group 1 (1-13): nan\n",
      "P-value between Group 3 (127-179) and Group 2 (14-126): nan\n",
      "P-value between Group 3 (127-179) and Group 3 (127-179): nan\n",
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # تبدیل نتایج Dunn's Test به یک DataFrame ۳x۳\n",
    "        dunn_results_df = pd.DataFrame(dunn_results, columns=[group1_name, group2_name, group3_name], index=[group1_name, group2_name, group3_name])\n",
    "        \n",
    "        # نمایش پی‌ویِی‌ها بین هر دو گروه\n",
    "        for row in dunn_results_df.index:\n",
    "            for col in dunn_results_df.columns:\n",
    "                print(f\"P-value between {row} and {col}: {dunn_results_df.loc[row, col]}\")\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results_df\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame برای نتایج پس‌هاک\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2a4def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Hoc Results for Somatomotor Network:\n",
      "                   Group 1 (1-13)  Group 2 (14-126)  Group 3 (127-179)\n",
      "Group 1 (1-13)                NaN               NaN                NaN\n",
      "Group 2 (14-126)              NaN               NaN                NaN\n",
      "Group 3 (127-179)             NaN               NaN                NaN\n",
      "\n",
      "\n",
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/posthoc_results.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # تبدیل نتایج Dunn's Test به یک DataFrame ۳x۳\n",
    "        dunn_results_df = pd.DataFrame(dunn_results, columns=[group1_name, group2_name, group3_name], index=[group1_name, group2_name, group3_name])\n",
    "        \n",
    "        # نمایش نتایج پس‌هاک در قالب ماتریس ۳x۳\n",
    "        print(f\"Post-Hoc Results for {health_status}:\")\n",
    "        print(dunn_results_df)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results_df\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame برای نتایج پس‌هاک\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/posthoc_results.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0171e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Hoc Results for Default Network:\n",
      "P-value between Group 1 (1-13) and Group 1 (1-13): nan\n",
      "P-value between Group 1 (1-13) and Group 2 (14-126): nan\n",
      "P-value between Group 1 (1-13) and Group 3 (127-179): nan\n",
      "P-value between Group 2 (14-126) and Group 1 (1-13): nan\n",
      "P-value between Group 2 (14-126) and Group 2 (14-126): nan\n",
      "P-value between Group 2 (14-126) and Group 3 (127-179): nan\n",
      "P-value between Group 3 (127-179) and Group 1 (1-13): nan\n",
      "P-value between Group 3 (127-179) and Group 2 (14-126): nan\n",
      "P-value between Group 3 (127-179) and Group 3 (127-179): nan\n",
      "Post-Hoc Results for Limbic Network:\n",
      "P-value between Group 1 (1-13) and Group 1 (1-13): nan\n",
      "P-value between Group 1 (1-13) and Group 2 (14-126): nan\n",
      "P-value between Group 1 (1-13) and Group 3 (127-179): nan\n",
      "P-value between Group 2 (14-126) and Group 1 (1-13): nan\n",
      "P-value between Group 2 (14-126) and Group 2 (14-126): nan\n",
      "P-value between Group 2 (14-126) and Group 3 (127-179): nan\n",
      "P-value between Group 3 (127-179) and Group 1 (1-13): nan\n",
      "P-value between Group 3 (127-179) and Group 2 (14-126): nan\n",
      "P-value between Group 3 (127-179) and Group 3 (127-179): nan\n",
      "نتایج پس‌هاک در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در یک لیست\n",
    "posthoc_results = []\n",
    "\n",
    "# تابع برای انجام آزمون‌های پس‌هاک\n",
    "def perform_posthoc(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون Kruskal-Wallis\n",
    "    h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "    \n",
    "    # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "    if p_value < 0.05:\n",
    "        # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "        data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "        labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "        \n",
    "        # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "        dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        \n",
    "        # تبدیل نتایج Dunn's Test به یک DataFrame ۳x۳\n",
    "        dunn_results_df = pd.DataFrame(dunn_results, columns=[group1_name, group2_name, group3_name], index=[group1_name, group2_name, group3_name])\n",
    "        \n",
    "        # نمایش مقادیر P-value بین هر دو گروه\n",
    "        print(f\"Post-Hoc Results for {health_status}:\")\n",
    "        for row in dunn_results_df.index:\n",
    "            for col in dunn_results_df.columns:\n",
    "                print(f\"P-value between {row} and {col}: {dunn_results_df.loc[row, col]}\")\n",
    "        \n",
    "        # ذخیره نتایج پس‌هاک در لیست\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': dunn_results_df\n",
    "        })\n",
    "    else:\n",
    "        posthoc_results.append({\n",
    "            'Health Status': health_status,\n",
    "            'Post-Hoc Results': \"No significant differences found\"\n",
    "        })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # انجام آزمون‌های پس‌هاک برای مقایسه گروه‌ها\n",
    "    perform_posthoc(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج پس‌هاک به DataFrame برای نتایج پس‌هاک\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# ذخیره نتایج پس‌هاک در فایل Excel\n",
    "posthoc_output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient2/posthoc_results.xlsx\"\n",
    "posthoc_results_df.to_excel(posthoc_output_path, index=False)\n",
    "\n",
    "print(f\"نتایج پس‌هاک در فایل {posthoc_output_path} ذخیره شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed1f2129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحلیل‌ها انجام شد و نتایج در فایل D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/analysis_results3_withPosthoc3.xlsx ذخیره شد.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# بارگذاری داده‌ها از فایل اکسل\n",
    "input_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/individual_means.xlsx\"\n",
    "data = pd.read_excel(input_path, sheet_name=None)\n",
    "\n",
    "# ذخیره نتایج آماری در یک لیست\n",
    "results = []\n",
    "\n",
    "# تابع برای انجام تحلیل و محاسبه آمار\n",
    "def analyze_group_statistics(group1_data, group2_data, group3_data, group1_name, group2_name, group3_name, health_status):\n",
    "    # انجام آزمون نرمال بودن (Shapiro-Wilk)\n",
    "    shapiro_group1_stat, shapiro_group1_p = shapiro(group1_data)\n",
    "    shapiro_group2_stat, shapiro_group2_p = shapiro(group2_data)\n",
    "    shapiro_group3_stat, shapiro_group3_p = shapiro(group3_data)\n",
    "\n",
    "    # انتخاب تست آماری بر اساس نتایج شاپیرو\n",
    "    if shapiro_group1_p > 0.05 and shapiro_group2_p > 0.05 and shapiro_group3_p > 0.05:\n",
    "        # داده‌ها نرمال هستند، از ANOVA استفاده می‌کنیم\n",
    "        f_stat, p_value = f_oneway(group1_data, group2_data, group3_data)\n",
    "        test_used = \"ANOVA\"\n",
    "        \n",
    "        # اگر ANOVA معنی‌دار است، از آزمون Tukey's HSD برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            tukey = pairwise_tukeyhsd(data_combined, labels, alpha=0.05)\n",
    "            tukey_results = tukey.summary()\n",
    "        else:\n",
    "            tukey_results = \"No significant differences found\"\n",
    "        \n",
    "    else:\n",
    "        # داده‌ها نرمال نیستند، از Kruskal-Wallis استفاده می‌کنیم\n",
    "        h_stat, p_value = kruskal(group1_data, group2_data, group3_data)\n",
    "        test_used = \"Kruskal-Wallis\"\n",
    "        \n",
    "        # اگر Kruskal-Wallis معنی‌دار است، از آزمون Dunn's Test برای مقایسه پس‌هاک استفاده می‌کنیم\n",
    "        if p_value < 0.05:\n",
    "            # اجرای Dunn's Test با استفاده از scikit-posthocs\n",
    "            data_combined = pd.concat([group1_data, group2_data, group3_data], axis=0)\n",
    "            labels = [group1_name] * len(group1_data) + [group2_name] * len(group2_data) + [group3_name] * len(group3_data)\n",
    "            \n",
    "            # استفاده از posthoc_dunn برای مقایسه پس‌هاک\n",
    "            dunn_results = sp.posthoc_dunn([group1_data, group2_data, group3_data], p_adjust='bonferroni')\n",
    "        else:\n",
    "            dunn_results = \"No significant differences found\"\n",
    "\n",
    "    # محاسبه میانگین و انحراف معیار برای هر گروه\n",
    "    group1_mean = group1_data.mean()\n",
    "    group2_mean = group2_data.mean()\n",
    "    group3_mean = group3_data.mean()\n",
    "    group1_std = group1_data.std()\n",
    "    group2_std = group2_data.std()\n",
    "    group3_std = group3_data.std()\n",
    "\n",
    "    # ذخیره نتایج در لیست\n",
    "    results.append({\n",
    "        'Health Status': health_status,\n",
    "        'Group1': group1_name,\n",
    "        'Group2': group2_name,\n",
    "        'Group3': group3_name,\n",
    "        'Group1 Mean': group1_mean,\n",
    "        'Group2 Mean': group2_mean,\n",
    "        'Group3 Mean': group3_mean,\n",
    "        'Group1 Std': group1_std,\n",
    "        'Group2 Std': group2_std,\n",
    "        'Group3 Std': group3_std,\n",
    "        'Shapiro Group1 p-value': shapiro_group1_p,\n",
    "        'Shapiro Group2 p-value': shapiro_group2_p,\n",
    "        'Shapiro Group3 p-value': shapiro_group3_p,\n",
    "        'p-value (ANOVA/Kruskal-Wallis)': p_value,\n",
    "        'Test Used': test_used,\n",
    "        'Post-Hoc Results': tukey_results if test_used == \"ANOVA\" else dunn_results  # نتایج پس‌هاک\n",
    "    })\n",
    "\n",
    "# انجام تحلیل برای تمام شیت‌ها (برای هر فایل)\n",
    "for sheet_name, df in data.items():\n",
    "    # تقسیم داده‌ها به سه گروه\n",
    "    group1_data = df.iloc[:13]['Individual Means']  # گروه اول: 13 نفر\n",
    "    group2_data = df.iloc[13:126]['Individual Means']  # گروه دوم: 113 نفر\n",
    "    group3_data = df.iloc[126:179]['Individual Means']  # گروه سوم: 53 نفر (از 127 تا 179)\n",
    "\n",
    "    # تحلیل آماری برای مقایسه گروه‌ها\n",
    "    analyze_group_statistics(group1_data, group2_data, group3_data, \"Group 1 (1-13)\", \"Group 2 (14-126)\", \"Group 3 (127-179)\", sheet_name)\n",
    "\n",
    "# تبدیل نتایج به DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ذخیره نتایج در فایل Excel\n",
    "output_path = r\"D:/DOC Aarabi/parkinson/new paper/new13-06/text/ALL EXEL SUBNETWORKS GRADIENT/Gradient3/analysis_results3_withPosthoc3.xlsx\"\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"تحلیل‌ها انجام شد و نتایج در فایل {output_path} ذخیره شد.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
